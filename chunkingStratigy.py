
from langchain_community.chat_models import ChatOllama

# 5. Agentic Chunking
print("#### Proposition-Based Chunking ####")

# https://arxiv.org/pdf/2312.06648.pdf

from langchain_openai import ChatOpenAI
from langchain.chains import create_extraction_chain_pydantic
from pydantic import BaseModel
from langchain import hub
    
# text = """
# ĐẠI HỌC QUỐC GIA TP. HỒ CHÍ MINH CỘNG HÒA XÃ HỘI CHỦ NGHĨA VIỆT NAM\nTRƯỜNG ĐẠI HỌC Độc Lập - Tự Do - Hạnh Phúc\nCÔNG NGHỆ THÔNG TIN\nĐỀ CƯƠNG CHI TIẾT\nTÊN ĐỀ TÀI: ỨNG DỤNG CÔNG NGHỆ TẠO SINH TĂNG CƯỜNG TRONG\nCẢI THIỆN KHẢ NĂNG TỰ HỌC VÀ RA QUYẾT ĐỊNH CHO TRỢ LÝ ẢO\nTÊN ĐỀ TÀI (tiếng Anh): RETRIEVAL-AUGMENTED GENERATION\nTECHNOLOGY IN IMPROVING SELF-LEARNING CAPABILITIES AND\nDECISION MAKING FOR VIRTUAL ASSISTANTS\nCán bộ hướng dẫn: ThS. Nguyễn Văn Kiệt\nThời gian thực hiện:Từ ngày 07/2024 đến ngày 12/2024\nSinh viên thực hiện:\n<Phạm Doãn Cảnh – 21520642>\nNội dung đề tài:(Mô tả chi tiết mục tiêu, phạm vi, đối tượng, phương pháp thực hiện,\nkết quả mong đợi của đề tài)\nA. Lý do chọn đề tài:\nKhái niệm trợ lý ảo trí tuệ nhân tạo là một trong những ứng dụng rất được quan tâm trong\nnhững nămgần đâyvì khảnăngvà sựtiện dụngmà cácứng dụngnàyđem đếnchongười dùng,\nlấycảm hứngtừcác nhân vậthư cấunhư J.A.R.V.I.Strong Vũ trụĐiện ảnhMarvel,hiện nayđã\nvà đang có rất nhiều nghiên cứu tậptrung vàophát triểnnhữnghệ thốngmôphỏngcũngnhư là\ncải tiến một trong số các tính năng được lấy ý tưởng từ các trợ lýảo trênđểgiải quyếtvàgiúp\ních cho một số vấn đề cụ thể trong cuộc cuộc sống con người hiện nay như công trình nghiên\ncứu của S. Siddesh và cộng sự năm 2020 [1] với công trình Dũngvà cộngsự năm2022[2] tập\ntrung nghiên cứu về khả năng nhận diện giọng nói tự động,chophépngười dùng cóthể không\ncần phải thao tác thủcông trênmànhình khitươngtác với trợ lýảo,RohitTamrakarvàcộng sự\nnăm 2021 [3] nghiên cứu về hệ thống chatbot tích hợp qua các ứng dụng nền tảng như Slack,\nWhatsApp, Telegram,…\nTận dụng các ý tưởng trên đề tài đề xuất một giải pháp mang tính ứng dụng để giải quyết\ncác vấn đề cụ thể trong cuộc sống của người dùng qua việc xây dựng hệ thống trợ lý ảo chạy\ntrên nền tảng chính là web, ngoài các khảnăng đãđượcnghiên cứu trênđềtài cũngnghiêncứu\nvề pháttriểncác khảnăngtương tác hỏiđápnhậndiện bốicảnh thôngquagọivideo haychia sẻ\nmàn hình từ người dùng, thực hiện tìm kiếm vàtổng hợpthông tinđanguồn,tự độngphântích\nvà học tập các thông tin dữ liệu cần thiết thông qua các cuộc trò chuyện và đồng thời có thể\nquản lýlịch trình, giờ giấclối sốngcủangười dùngmộtcách hiệu quả.B. Mục tiêu đề tài:\nXây dựng một hệ thống trợ lý ảo đa ngôn ngữ, hỗ trợ người dùng trong việc tự động\nhoá quá trình quản lý lịch trình cá nhân, tìm kiếm tổng hợp và tóm tắt thông tin từ\nnhiều nguồn. Đề tài hướng đến việc cải thiện trải nghiệm người dùng, rút ngắn rào cản\ngiữa con người và máy móc thông qua việc tương tác và điều khiển bằng giọng nói\ntích hợp với khả năng nhận diện, hiểu biết bối cảnh qua thị giác từ trợ lý ảo. Đồng thời\ncung cấp khả năng tự động phân tích và ghi nhớ các thông tin quan trọng liên quan\nđến người dùng thông qua bộ nhớ dài hạn được lưu trữ vào cơ sở dữ liệu, giúp cho AI\ncó thể đưa ra những câu trả lời mang những thông tin riêng biệt và phù hợp hơn với\ntừng người dùng cụ thể qua quá trình tương tác, từ đó tăng cường tính linh hoạt và\nhiệu quả trong việc giải quyết các vấn đề của người dùng.\nC. Phạm vi và đối tượng:\nTập trung nghiên cứu xây dựng một hệ thống tận dụng AI tạo sinh kết hợp công\nnghệ “Retrieval-augmented generation” để xây dựng nên một trợ lý ảo có khả năng ghi\nnhớ và học hỏi từ đó mang lại hiệu quả linh hoạt hơn trong việc hỗ trợ người dùng xây\ndựng, quản lý lịch trình học tập và làm việc, tự động nhắc nhở các nhiệm vụ cần làm.\nĐồng thời cung cấp khả năng tìm kiếm và tổng hợp thông tin từ internet hay từ một\nhoặc nhiều tập dữ liệu, tài liệu một cách nhanh chóng và chính xác, với trải nghiệm\ngần gũi và dễ tương tác giữa người và máy tính thông qua khả năng lắng nghe và quan\nsát bối cảnh xung quanh môi trường tương tác.\nD. Phương pháp thực hiện:Hình1:Môhìnhtổngquancáchthứctriểnkhaicủahệthống\nMô hình trong Hình 1 trình bày rõ về quy trình hoạt động của trợ lý ảo và các công nghệ\nđược tích hợp. Bao gồm 4 giai đoạn chính: (1) Xử lý và phân tích thông tin được tiếp\nnhận; (2) Phân tích và đồng bộ dữ liệu hội thoại; (3) Phân tích yêu cầu và xử lý kết quả;\n(4) Xuất dữ liệu.\nI. Xử lý và phân tích thông tin được tiếp nhận:\nQuá trình này tiếp nhận thông tin đầu vào qua các phương thức tương tác: bằng văn bản,\nfile, hình ảnh, một url bất kỳ, giọng nói và đặc biệt là khả năng tương tác trực tiếp qua\nviệc gọi video và chia sẻ màn hình. Sự linh hoạt này cho phép hệ thống tương tác với\nngười dùng trong nhiều hoàn cảnh và lĩnh vực khác nhau, từ đó nâng cao khả năng tiếp\ncận và phản hồi trước yêu cầu đa dạng của người dùng:a. Tương tác qua giọng nói:\nTận dụng chức năng từ opensource silence-aware-recorder để giải quyết vấn đề về việc\nkhi nào nên ngừng ghi âm và bắt đầu gọi API. Đây là một nguồn mở cho phép nhận diện\nkhi người dùng ngừng nói trong một khoảng thời gian nhất định, giúp người dùng không\ncần thao tác thủ công. Với khả năng nhận diện đa ngôn ngữ của mô hình Whisper được\ncung cấp bởi OpenAI, công nghệ này xử lý quá trình chuyển đổi từ giọng nói thành văn\nbản một cách chính xác giải quyết cho vấn đề nhận diện đa ngôn ngữ cho trợ lý ảo.\nb. Tương tác qua gọi video và chia sẻ màn hình:\nĐối với vấn đề về việc làm sao để một trợ lý ảo có thể nhận diện bối cảnh và tương tác\nvới lượng dữ liệu trong quá trình gọi video và chia sẻ màn hình liên tục. Việc tích hợp\nkhả năng cho phép xử lý dữ liệu đầu vào thông qua thị giác trực tiếp với mô hình ngôn\nngữ lớn để nhận biết bối cảnh vẫn là một nhiệm vụ khó khăn và nhiều hạn chế chẳng hạn\nnhư giới hạn về lượng “context window” của một mô hình ngôn ngữ làm cho việc xử lý\nliên tục khối lượng lớn dữ liệu như một video trong một lần rất là khó khăn.\nỞ đề tài này đề xuất một giải pháp để xử lý cho vấn đề trên bằng cách chuyển đổi video\nthành từng frame và sử dụng khả năng nhận diện khi người dùng ngừng nói, như đã đề\ncập ở phần tương tác bằng giọng nói, để xây dựng và mô phỏng quá trình ghi nhận thông\ntin bối cảnh từ người dùng đang tương tác.\nHình2:Chuyểnđổivideothànhmộttấmảnhtừcácframeskhoảnhkhắc\nDữ liệu video trong quá trình tương tác sẽ được ghi nhận và tổng hợp thành tối đa 60\nkhung hình gần nhất. Các khung hình này sau đó sẽ được gộp lại thành một tấm ảnh\ndạng lưới thể hiện các khoảnh khắc chuyển động trong một bức ảnh duy nhất từ đó giúp\nmô hình có thể dễ dàng nhận diện và phân tích để đưa ra câu trả lời.\nc. Tiền xử lý fileHình3:TổngquanphươngphápAgenticchunking\nCác tập dữ liệu lớn sẽ được tiền xử lý bằng cách chia nhỏ toàn bộ nội dung của thành các\nchunk thông qua phương pháp phân đoạn nội dung (chunking) để chia văn bản thành các\nchunk có ý nghĩa, hoàn chỉnh về mặt ngữ nghĩa. Tận dụng phương pháp proposal-based\nchunking từ Agentic chunking được nghiên cứu từ công trình của Tong Chen và cộng sự\nnăm 2023 [7] để giúp cho các phân đoạn văn bản nhỏ có thể đứng độc lập và cung cấp\nmột ý nghĩa hoàn chỉnh mà không cần phụ thuộc vào các yếu tố diễn giải từ các đoạn\nvăn bản trước đó. Cách tiếp cận này đảm bảo tính toàn vẹn của thông tin trong quá trình\ntruy xuất, giúp cho kết quả chính xác hơn và phù hợp với ngữ cảnh hơn. Các chunk này\nsau đó sẽ được chuyển đổi dưới dạng các vector bằng mô hình embedding\ntext-embedding-3-large từ OpenAI và lưu trữ dưới vector database để phục vụ cho việc\nhỏi đáp sau này.\nII. Phân tích và đồng bộ dữ liệu hội thoại\nNgoài khả năng ghi nhớ thông tin trong lịch sử của từng cuộc hội thoại như các trợ lý ảo\nhiện nay, để mô phỏng lại khả năng ghi nhớ của con người cho trợ lý ảo và cải thiện điều\nđó, đề tài triển khai hai phương thức để phân tích xử lý thông tin cho bộ nhớ dài hạn và\nbộ nhớ ngắn hạn cho trợ lý ảo\na. Phân tích và xử lý thông tin cho bộ nhớ dài hạn(Long term Memory)\nÁp dụng kỹ thuật Tree of Thought Prompting (ToT) trong Prompt Engineering được\nnghiên cứu bởi Shunyu Yao và cộng sự năm 2023 [4] và nghiên cứu của JieyiLongnăm\n2023 [5], đây là kĩ thuật cho phép mô hình ngôn ngữ khám phá nhiều nhánh suy luận\nkhác nhau, đánh giá các quyết định từ đó cải thiện khả năng giải quyết vấn đề của các\nmô hình ngôn ngữ lớn, từ đây đề tài xây dựng nên khả năng ghi nhớ dài hạn cho phép trợ\nlý ảo từ việc việc phân tích nội dung từ người dùng thông qua nhiều bước để đưa ra các\nquyết định lưu trữ, học tập và truy xuất lại các thông tin đã được học từ các cuộc hộithoại trước, giúp nâng cao tính linh hoạt và khả năng phản hồi chính xác, tăng trải\nnghiệm hơn cho người dùng.\nHình4:Quytrìnhphântíchvàtìmkiếmbộthôngtinchobộnhớdàihạn\nGồm có hai quy trình chính để xử lý quá trình lưu trữ dài hạn này, đó là “phân tích để lấy\ndữ liệu liên quan từ vector database" và "phân tích để lưu trữ vào bộ nhớ", hai quy trình\nnày cùng góp phần vào khả năng ghi nhớ và sử dụng thông tin của trợ lý ảo, mỗi quy\ntrình tập trung vào một khía cạnh khác nhau của việc quản lý thông tin.\n● Phân tích để lưu trữ vào bộ nhớ (Memo Storage): Thông qua mô hình\ngpt4o-mini prompt từ người dùng sẽ được chia ra và phân tích lần lượt dựa theo\ncác tiêu chí nhỏ để đánh giá nội dung có liên quan đến người dùng và có ích cho\nviệc sử dụng sau này không, nếu các kết quả phân tích đều thoả mãn, mô hình sẽ\ndựa trên prompt của người để phân tích và trích xuất ra cặp câu trả lời và một lời\nkhuyên liên quan đến câu trả lời đó để lưu trữ cặp dữ liệu đấy vào cơ sở dữ liệu\nvector.\n● Phân tích để lấy dữ liệu liên quan từ vector database (Memo Retrieval): Mô\nhình gpt4o-mini sẽ phân tích prompt đầu vào để xác định các khía cạnh quan\ntrọng của tin nhắn. sau đó sử dụng tin nhắn hoặc các phần tổng quát hóa của nó để\ntìm kiếm các memo liên quan trong cơ sở dữ liệu vector. Các dữ liệu được truy\nxuất sẽ được so sánh với tin nhắn hiện tại để đảm bảo chúng đủ liên quan. Các dữ\nliệu có khoảng cách nhỏ hơn ngưỡng xác định trước từ trong vector database sẽ\nđược chọn lọc và trở thành dữ liệu bộ nhớ có liên quan và sẽ được sử dụng để bổ\nsung vào ngữ cảnh cuộc trò chuyện hiện tại, giúp mô hình có thể trả lời câu hỏi\ncủa người dùng một cách chính xác và cụ thể hơn.b. Phân tích và xử lý thông tin cho bộ nhớ ngắn hạn\nBộ nhớ ngắn hạn bao gồm dữ liệu được tóm tắt lại từ toàn bộ lịch sử của các lần trò\nchuyện trước đó giữa người dùng và trợ lý ảo để giúp cho mô hình có thể nhận biết được\ntổng quan về cuộc trò chuyện trước đó, bên cạnh đó bộ nhớ ngắn hạn cũng bao gồm các\ndữ liệu "instruction prompt" liên quan đến ngày tháng hiện tại hay các thiết lập về tính\ncách và chỉ dẫn mà trợ lý ảo phải tuân theo.\nIII. Phân tích yêu cầu và xử lý kết quả\nTận dụng chức năng tool calling của mô hình gpt4-o với khả năng nhận diện và phân\ntích prompt từ yêu cầu mà người dùng đang hướng đến để xem xét việc sử dụng sự trợ\ngiúp từ các công cụ đã được thiết lập sẵn cho trợ lý ảo\na. Đặt lịch nhắc nhở, lên kế hoạch:\nHình5:Quytrìnhlênkếhoạch/lịchhẹncủatrợlýảo\nỨng dụng từ công trình nghiên cứu của Nitarshan Rajkumar và cộng sự năm 2022 [6], sử\ndụng phương pháp chuyển đổi từ text sang sql và khả năng tương tác với cơ sở dữ liệu\ntrong phạm vi các table lưu trữ dữ liệu nhắc nhở từ langchain cho phép mô hình có thể\nthực hiện các thao tác tìm kiếm thêm xóa sửa đối với các dữ liệu nhắc nhở dựa trên\nprompt của người dùng, đồng thời dữ liệu các lịch nhắc nhở sẽ luôn được đồng bộ lên\ngoogle calendar tương ứng với tài khoản google đã được liên kết với tài khoản hiện tại\nđang tương tác với trợ lý ảo, với tính năng parallel tool calling cho phép mô hình có thể\nthực hiện quá trình thêm bớt hay điều chỉnh dữ liệu nhắc nhở nhiều lần, điều này mang\nlại cho trợ lý ảo khả năng thiết lập hay lên một lịch trình học tập, làm việc một cách tự\nđộng và nhanh chóng\nb. Phân tích tìm kiếm thông tin từ internet:Hình6:Quytrìnhtìmkiếmthôngtintừinternetcủatrợlýảo\nVới các yêu cầu đòi hỏi những thông tin mang tính chính xác thời gian thực, các dữ liệu\nmang tính biến động nhiều và nằm ngoài dữ liệu được huấn luyện của mô hình, trợ lý ảo\nsẽ trực tiếp tìm kiếm và phân tích các thông tin từ internet để trả lời thông qua quy trình\nsau:\n- Bước 1: Thực hiện tìm kiếm các kết quả từ Google thông qua Serper API. Mô\nhình sẽ tự động phân tích các từ khóa liên quan đến câu hỏi từ prompt để thực\nhiện việc tìm kiếm.\n- Bước 2: Sau khi có được các URL cần thiết, sử dụng công cụ Puppeteer để scrape\ntoàn bộ nội dung từ các trang web.\n- Bước 3: Tiến hành tóm tắt, lại số dữ liệu vừa scrape được, để đảm bảo token tối\nđa cho phép với kỹ thuật map reduce từ Langchain để thực hiện tóm tắt tất cả dữ\nliệu cần thiết\n- Bước 4: Mô hình sẽ phân tích dữ liệu cuối cùng để đánh giá tính đáp ứng với câu\nhỏi. Nếu không đáp ứng, quy trình sẽ quay lại từ bước 1, tìm kiếm theo từ khóa\nkhác và lặp lại cho đến khi có câu trả lời phù hợp. Sau đó, mô hình ngôn ngữ sẽ\nđiều chỉnh lại câu từ để đưa ra thông tin tóm gọn mà người dùng mong muốn.\nVới mỗi câu trả lời liên quan đến việc tìm kiếm từ internet, trợ lý ảo sẽ luôn đính kèm\nđường link nguồn từ các trang web có kết quả phù hợp.\nc. Hỏi đáp về nội dung liên quan đến các file đã được phân tích\nỨng dụng công nghệ tạo sinh có tăng cường truy xuất (Retrieval Augmented\nGeneration) để có thể giúp cho mô hình ngôn ngữ có thể đưa ra các câu trả lời dựa trên\nnguồn kiến thức từ các tập dữ liệu lớn đã được phân tích trước đó và phòng tránh các\ntrường hợp “Hallucination”. Do đó với các trường hợp prompt yêu cầu trả lời về các\nthông tin liên quan đến nội dung từ các file đã được tải lên, trợ lý ảo sẽ thực hiện cơ chế\nretrieval quét toàn bộ vector trong database để xác định các phân đoạn tri thức\n(paragraphs) nào có ngữ nghĩa tương đồng với câu truy vấn của người dùng. Các\nparagraphs này sau đó được vào LLM để làm tăng context cho quá trình sinh ra câu trả\nlời, sau đó các paragraphs này được kết hợp với câu query ban đầu của user tạo thành 1câu prompt. Câu prompt này được bổ sung thêm context sau đó được đưa qua LLM để\nsinh ra câu phản hồi cuối cùng theo context bổ sung.\nIV. Xuất dữ liệu\nTận dụng khả năng hỗ trợ chunk stream từ mô hình ngôn ngữ, đề tài ứng dụng socket để\nhỗ trợ khả năng gửi liên tục các dữ liệu chunk được tạo ra về giao diện, đối với các\ntrường hợp mô hình yêu cầu sử dụng tool, socket cũng sẽ thực hiện trả về dữ liệu và quá\ntrình xử lý của các tool đó, điều này cho phép người dùng có thể nắm bắt được quá trình\nxử lý của trợ lý ảo và đặc biệt là giúp tăng trải nghiệm sử dụng, người dùng không cần\nphải đợi toàn bộ quá trình xử lý hoàn thành mà vẫn có thể giám sát được quy trình xử lý\nkhi đang tương tác trên giao diện ứng dụng.\nĐối với tính năng gọi video, đề tài áp dụng phương pháp chia nhỏ câu trả lời ra thành\nnhiều chunk từ đó sử dụng mô hình chuyển đổi tts-1 của openAI để chuyển đổi lần lượt\ncác dạng dữ liệu văn bản sang dữ liệu âm thanh, các dữ liệu âm thành này sau đó sẽ được\nphát lần lượt cho người dùng, quá trình này cho phép tối ưu được tổng thời gian xử lý\ncủa quá trình chuyển đổi bằng việc mô hình sẽ tốn ít thời gian để xử lý từng cụm dữ liệu\nnhỏ hơn là xử lý một lượng lớn dữ liệu trong một lần.\nE. Kết quả mong đợi:\n- Xây dựng thành công một hệ thống website tích hợp trợ lý ảo bằng AI tạo sinh giúp rút\nngắn khoảng cách tương tác giữa người dùng và máy móc thông qua khả năng nhận diện\nbối cảnh bằng thị giác và khả năng ghi nhớ dài hạn của trợ lý ảo, từ đó mang lại trải\nnghiệm hỗ trợ người dùng tốt hơn.\n- Triển khai áp dụng công nghệ tạo sinh có tăng cường truy xuất (Retrieval Augmented\nGeneration) kết hợp phương pháp proposal-based chunking để giúp tăng độ tin cậy cho\ncác đoạn dữ liệu được lưu vào vector database giúp cho mô hình có thể đưa vào các câu\ntrả lời chính xác hơn dựa trên các bộ dữ liệu đó.\n- Áp dụng thành công kĩ thuật như Tree of Thought Prompting (ToT) trong Prompt\nEngineering, giúp cho mô hình có thể tổ chức các chuỗi lập luận để phân tích và đưa ra\ncác quyết định chính xác trong việc ghi nhớ học tập thông tin từ người dùng, kết hợp với\nkhả năng retrieve từ vector database để đưa ra các thông tin từ các dữ liệu liên quan đến\nmục tiêu người dùng đang hướng đến.\n- Xây dựng thành công khả năng tìm kiếm thông tin từ internet để giúp trợ lý ảo có thể\nđưa ra những câu trả lời mang tính chất thời gian thực giúp người dùng nhanh chóng tiếp\n- Giải quyết cho bài toán tự động hoá quá trình lập kế hoạch với khả năng điều chỉnh lịch\ntrình tự động, đồng bộ với Google Calendar.F. Tài liệu tham khảo:\n[1] S. Siddesh, A. Ullas, B. Santosh, Artificial intelligence based voice assistant, tập\n978–1–7281–68234/20, IEEE,2020,p.593–596.\n[2] Nguyễn Tiến Dũng, Phạm Trung Thiên*, Lê Ngọc Dũng, Đỗ Văn Tỉnh,Vũ Xuân Tú,\nNguyễn Văn Hiệp, Nguyễn Ngọc Thể, NGHIÊN CỨU TRỢ LÝ ẢO ỨNG DỤNG TRÍ\nTUỆ NHÂNTẠO,Hồ ChíMinh: KHOAHỌC&CÔNG NGHỆ,2022.\n[3] Rohit Tamrakar, Niraj Wani, Design and Development of CHATBOT: AReview, Bhopal:\nINTERNATIONAL CONFERENCE On “Latest Trends in Civil, Mechanical and\nElectrical Engineering”,2021.\n[4] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao,\nKarthik Narasimhan, “Tree of Thoughts: Deliberate Problem Solving with Large\nLanguageModels”, 3Dec2023.\n[5] JieyiLong, “LargeLanguageModel GuidedTree-of-Thought”, 15May2023.\n[6] Nitarshan Rajkumar, Raymond Li, and Dzmitry Bahdanau. n.d. “Evaluating the\nText-to-SQL Capabilities ofLarge LanguageModels.”, 15Mar2022\n[7] Tong Chen, Hongwei Wang, Sihao Chen, Wenhao Yu♢, Kaixin Ma, Xinran Zhao,\nHongming Zhang, and Dong Yu. 2023. “Dense X Retrieval: What Retrieval Granularity\nShould WeUse?”, 12/2023.\nKế hoạch thực hiện:\nMô tả tóm tắt kế hoạch làm việc: Kế hoạch làm việc được thể hiện trong bảng sau:\nBảng 1. Mô tả tóm tắt kế hoạch làm việc\nCông việc T9 T10 T11 T12 T1\nNghiên cứu các công trình liên quan\nThiết kế và nâng cấp hệ thống\nTriển khai hệ thống\nKiểm thử và đánh giá\nVận hành và bảo trì\nViết và hoàn thiện báo cáoBảng 2. Chi tiết bảng kế hoạch thực hiện\nCông việc Cảnh\nĐề ra mục tiêu và lên kế hoạch cụ thể X\nTìm hiểu và tham khảo nguồn tài liệu; nghiên cứu những X\nkiến thức liên quan\nXây dựng giao diện, thiết kế hệ thống tích hợp các dịch vụ và API X\nĐánh giá, phân tích kết quả X\nViết báo cáo và báo cáo X\nXác nhận của CBHD TP. HCM, ngày….tháng …..năm…..\n(Ký tênvàghi rõhọtên) Sinh viên\n(Ký tênvàghi rõhọtên)

# """

# text2 = """
# "ĐẠI HỌC QUỐC GIA TP. HỒ CHÍ MINH CỘNG HÒA XÃ HỘI CHỦ NGHĨA VIỆT NAM\nTRƯỜNG ĐẠI HỌC Độc Lập - Tự Do - Hạnh Phúc\nCÔNG NGHỆ THÔNG TIN\nĐỀ CƯƠNG CHI TIẾT\nTÊN ĐỀ TÀI: ỨNG DỤNG CÔNG NGHỆ TẠO SINH TĂNG CƯỜNG TRONG\nCẢI THIỆN KHẢ NĂNG TỰ HỌC VÀ RA QUYẾT ĐỊNH CHO TRỢ LÝ ẢO\nTÊN ĐỀ TÀI (tiếng Anh): RETRIEVAL-AUGMENTED GENERATION\nTECHNOLOGY IN IMPROVING SELF-LEARNING CAPABILITIES AND\nDECISION MAKING FOR VIRTUAL ASSISTANTS\nCán bộ hướng dẫn: ThS. Nguyễn Văn Kiệt\nThời gian thực hiện:Từ ngày 07/2024 đến ngày 12/2024\nSinh viên thực hiện:\n<Phạm Doãn Cảnh – 21520642>\nNội dung đề tài:(Mô tả chi tiết mục tiêu, phạm vi, đối tượng, phương pháp thực hiện,\nkết quả mong đợi của đề tài)\nA. Lý do chọn đề tài:\nKhái niệm trợ lý ảo trí tuệ nhân tạo là một trong những ứng dụng rất được quan tâm trong\nnhững nămgần đâyvì khảnăngvà sựtiện dụngmà cácứng dụngnàyđem đếnchongười dùng,\nlấycảm hứngtừcác nhân vậthư cấunhư J.A.R.V.I.Strong Vũ trụĐiện ảnhMarvel,hiện nayđã\nvà đang có rất nhiều nghiên cứu tậptrung vàophát triểnnhữnghệ thốngmôphỏngcũngnhư là\ncải tiến một trong số các tính năng được lấy ý tưởng từ các trợ lýảo trênđểgiải quyếtvàgiúp\ních cho một số vấn đề cụ thể trong cuộc cuộc sống con người hiện nay như công trình nghiên\ncứu của S. Siddesh và cộng sự năm 2020 [1] với công trình Dũngvà cộngsự năm2022[2] tập\ntrung nghiên cứu về khả năng nhận diện giọng nói tự động,chophépngười dùng cóthể không\ncần phải thao tác thủcông trênmànhình khitươngtác với trợ lýảo,RohitTamrakarvàcộng sự\nnăm 2021 [3] nghiên cứu về hệ thống chatbot tích hợp qua các ứng dụng nền tảng như Slack,\nWhatsApp, Telegram,…\nTận dụng các ý tưởng trên đề tài đề xuất một giải pháp mang tính ứng dụng để giải quyết\ncác vấn đề cụ thể trong cuộc sống của người dùng qua việc xây dựng hệ thống trợ lý ảo chạy\ntrên nền tảng chính là web, ngoài các khảnăng đãđượcnghiên cứu trênđềtài cũngnghiêncứu\nvề pháttriểncác khảnăngtương tác hỏiđápnhậndiện bốicảnh thôngquagọivideo haychia sẻ\nmàn hình từ người dùng, thực hiện tìm kiếm vàtổng hợpthông tinđanguồn,tự độngphântích\nvà học tập các thông tin dữ liệu cần thiết thông qua các cuộc trò chuyện và đồng thời có thể\nquản lýlịch trình, giờ giấclối sốngcủangười dùngmộtcách hiệu quả.B. Mục tiêu đề tài:\nXây dựng một hệ thống trợ lý ảo đa ngôn ngữ, hỗ trợ người dùng trong việc tự động\nhoá quá trình quản lý lịch trình cá nhân, tìm kiếm tổng hợp và tóm tắt thông tin từ\nnhiều nguồn. Đề tài hướng đến việc cải thiện trải nghiệm người dùng, rút ngắn rào cản\ngiữa con người và máy móc thông qua việc tương tác và điều khiển bằng giọng nói\ntích hợp với khả năng nhận diện, hiểu biết bối cảnh qua thị giác từ trợ lý ảo. Đồng thời\ncung cấp khả năng tự động phân tích và ghi nhớ các thông tin quan trọng liên quan\nđến người dùng thông qua bộ nhớ dài hạn được lưu trữ vào cơ sở dữ liệu, giúp cho AI\ncó thể đưa ra những câu trả lời mang những thông tin riêng biệt và phù hợp hơn với\ntừng người dùng cụ thể qua quá trình tương tác, từ đó tăng cường tính linh hoạt và\nhiệu quả trong việc giải quyết các vấn đề của người dùng.\nC. Phạm vi và đối tượng:\nTập trung nghiên cứu xây dựng một hệ thống tận dụng AI tạo sinh kết hợp công\nnghệ “Retrieval-augmented generation” để xây dựng nên một trợ lý ảo có khả năng ghi\nnhớ và học hỏi từ đó mang lại hiệu quả linh hoạt hơn trong việc hỗ trợ người dùng xây\ndựng, quản lý lịch trình học tập và làm việc, tự động nhắc nhở các nhiệm vụ cần làm.\nĐồng thời cung cấp khả năng tìm kiếm và tổng hợp thông tin từ internet hay từ một\nhoặc nhiều tập dữ liệu, tài liệu một cách nhanh chóng và chính xác, với trải nghiệm\ngần gũi và dễ tương tác giữa người và máy tính thông qua khả năng lắng nghe và quan\nsát bối cảnh xung quanh môi trường tương tác.\nD. Phương pháp thực hiện:Hình1:Môhìnhtổngquancáchthứctriểnkhaicủahệthống\nMô hình trong Hình 1 trình bày rõ về quy trình hoạt động của trợ lý ảo và các công nghệ\nđược tích hợp. Bao gồm 4 giai đoạn chính: (1) Xử lý và phân tích thông tin được tiếp\nnhận; (2) Phân tích và đồng bộ dữ liệu hội thoại; (3) Phân tích yêu cầu và xử lý kết quả;\n(4) Xuất dữ liệu.\nI. Xử lý và phân tích thông tin được tiếp nhận:\nQuá trình này tiếp nhận thông tin đầu vào qua các phương thức tương tác: bằng văn bản,\nfile, hình ảnh, một url bất kỳ, giọng nói và đặc biệt là khả năng tương tác trực tiếp qua\nviệc gọi video và chia sẻ màn hình. Sự linh hoạt này cho phép hệ thống tương tác với\nngười dùng trong nhiều hoàn cảnh và lĩnh vực khác nhau, từ đó nâng cao khả năng tiếp\ncận và phản hồi trước yêu cầu đa dạng của người dùng:a. Tương tác qua giọng nói:\nTận dụng chức năng từ opensource silence-aware-recorder để giải quyết vấn đề về việc\nkhi nào nên ngừng ghi âm và bắt đầu gọi API. Đây là một nguồn mở cho phép nhận diện\nkhi người dùng ngừng nói trong một khoảng thời gian nhất định, giúp người dùng không\ncần thao tác thủ công. Với khả năng nhận diện đa ngôn ngữ của mô hình Whisper được\ncung cấp bởi OpenAI, công nghệ này xử lý quá trình chuyển đổi từ giọng nói thành văn\nbản một cách chính xác giải quyết cho vấn đề nhận diện đa ngôn ngữ cho trợ lý ảo.\nb. Tương tác qua gọi video và chia sẻ màn hình:\nĐối với vấn đề về việc làm sao để một trợ lý ảo có thể nhận diện bối cảnh và tương tác\nvới lượng dữ liệu trong quá trình gọi video và chia sẻ màn hình liên tục. Việc tích hợp\nkhả năng cho phép xử lý dữ liệu đầu vào thông qua thị giác trực tiếp với mô hình ngôn\nngữ lớn để nhận biết bối cảnh vẫn là một nhiệm vụ khó khăn và nhiều hạn chế chẳng hạn\nnhư giới hạn về lượng “context window” của một mô hình ngôn ngữ làm cho việc xử lý\nliên tục khối lượng lớn dữ liệu như một video trong một lần rất là khó khăn.\nỞ đề tài này đề xuất một giải pháp để xử lý cho vấn đề trên bằng cách chuyển đổi video\nthành từng frame và sử dụng khả năng nhận diện khi người dùng ngừng nói, như đã đề\ncập ở phần tương tác bằng giọng nói, để xây dựng và mô phỏng quá trình ghi nhận thông\ntin bối cảnh từ người dùng đang tương tác.\nHình2:Chuyểnđổivideothànhmộttấmảnhtừcácframeskhoảnhkhắc\nDữ liệu video trong quá trình tương tác sẽ được ghi nhận và tổng hợp thành tối đa 60\nkhung hình gần nhất. Các khung hình này sau đó sẽ được gộp lại thành một tấm ảnh\ndạng lưới thể hiện các khoảnh khắc chuyển động trong một bức ảnh duy nhất từ đó giúp\nmô hình có thể dễ dàng nhận diện và phân tích để đưa ra câu trả lời.\nc. Tiền xử lý fileHình3:TổngquanphươngphápAgenticchunking\nCác tập dữ liệu lớn sẽ được tiền xử lý bằng cách chia nhỏ toàn bộ nội dung của thành các\nchunk thông qua phương pháp phân đoạn nội dung (chunking) để chia văn bản thành các\nchunk có ý nghĩa, hoàn chỉnh về mặt ngữ nghĩa. Tận dụng phương pháp proposal-based\nchunking từ Agentic chunking được nghiên cứu từ công trình của Tong Chen và cộng sự\nnăm 2023 [7] để giúp cho các phân đoạn văn bản nhỏ có thể đứng độc lập và cung cấp\nmột ý nghĩa hoàn chỉnh mà không cần phụ thuộc vào các yếu tố diễn giải từ các đoạn\nvăn bản trước đó. Cách tiếp cận này đảm bảo tính toàn vẹn của thông tin trong quá trình\ntruy xuất, giúp cho kết quả chính xác hơn và phù hợp với ngữ cảnh hơn. Các chunk này\nsau đó sẽ được chuyển đổi dưới dạng các vector bằng mô hình embedding\ntext-embedding-3-large từ OpenAI và lưu trữ dưới vector database để phục vụ cho việc\nhỏi đáp sau này.\nII. Phân tích và đồng bộ dữ liệu hội thoại\nNgoài khả năng ghi nhớ thông tin trong lịch sử của từng cuộc hội thoại như các trợ lý ảo\nhiện nay, để mô phỏng lại khả năng ghi nhớ của con người cho trợ lý ảo và cải thiện điều\nđó, đề tài triển khai hai phương thức để phân tích xử lý thông tin cho bộ nhớ dài hạn và\nbộ nhớ ngắn hạn cho trợ lý ảo\na. Phân tích và xử lý thông tin cho bộ nhớ dài hạn(Long term Memory)\nÁp dụng kỹ thuật Tree of Thought Prompting (ToT) trong Prompt Engineering được\nnghiên cứu bởi Shunyu Yao và cộng sự năm 2023 [4] và nghiên cứu của JieyiLongnăm\n2023 [5], đây là kĩ thuật cho phép mô hình ngôn ngữ khám phá nhiều nhánh suy luận\nkhác nhau, đánh giá các quyết định từ đó cải thiện khả năng giải quyết vấn đề của các\nmô hình ngôn ngữ lớn, từ đây đề tài xây dựng nên khả năng ghi nhớ dài hạn cho phép trợ\nlý ảo từ việc việc phân tích nội dung từ người dùng thông qua nhiều bước để đưa ra các\nquyết định lưu trữ, học tập và truy xuất lại các thông tin đã được học từ các cuộc hộithoại trước, giúp nâng cao tính linh hoạt và khả năng phản hồi chính xác, tăng trải\nnghiệm hơn cho người dùng.\nHình4:Quytrìnhphântíchvàtìmkiếmbộthôngtinchobộnhớdàihạn\nGồm có hai quy trình chính để xử lý quá trình lưu trữ dài hạn này, đó là “phân tích để lấy\ndữ liệu liên quan từ vector database\" và \"phân tích để lưu trữ vào bộ nhớ\", hai quy trình\nnày cùng góp phần vào khả năng ghi nhớ và sử dụng thông tin của trợ lý ảo, mỗi quy\ntrình tập trung vào một khía cạnh khác nhau của việc quản lý thông tin.\n● Phân tích để lưu trữ vào bộ nhớ (Memo Storage): Thông qua mô hình\ngpt4o-mini prompt từ người dùng sẽ được chia ra và phân tích lần lượt dựa theo\ncác tiêu chí nhỏ để đánh giá nội dung có liên quan đến người dùng và có ích cho\nviệc sử dụng sau này không, nếu các kết quả phân tích đều thoả mãn, mô hình sẽ\ndựa trên prompt của người để phân tích và trích xuất ra cặp câu trả lời và một lời\nkhuyên liên quan đến câu trả lời đó để lưu trữ cặp dữ liệu đấy vào cơ sở dữ liệu\nvector.\n● Phân tích để lấy dữ liệu liên quan từ vector database (Memo Retrieval): Mô\nhình gpt4o-mini sẽ phân tích prompt đầu vào để xác định các khía cạnh quan\ntrọng của tin nhắn. sau đó sử dụng tin nhắn hoặc các phần tổng quát hóa của nó để\ntìm kiếm các memo liên quan trong cơ sở dữ liệu vector. Các dữ liệu được truy\nxuất sẽ được so sánh với tin nhắn hiện tại để đảm bảo chúng đủ liên quan. Các dữ\nliệu có khoảng cách nhỏ hơn ngưỡng xác định trước từ trong vector database sẽ\nđược chọn lọc và trở thành dữ liệu bộ nhớ có liên quan và sẽ được sử dụng để bổ\nsung vào ngữ cảnh cuộc trò chuyện hiện tại, giúp mô hình có thể trả lời câu hỏi\ncủa người dùng một cách chính xác và cụ thể hơn.b. Phân tích và xử lý thông tin cho bộ nhớ ngắn hạn\nBộ nhớ ngắn hạn bao gồm dữ liệu được tóm tắt lại từ toàn bộ lịch sử của các lần trò\nchuyện trước đó giữa người dùng và trợ lý ảo để giúp cho mô hình có thể nhận biết được\ntổng quan về cuộc trò chuyện trước đó, bên cạnh đó bộ nhớ ngắn hạn cũng bao gồm các\ndữ liệu \"instruction prompt\" liên quan đến ngày tháng hiện tại hay các thiết lập về tính\ncách và chỉ dẫn mà trợ lý ảo phải tuân theo.\nIII. Phân tích yêu cầu và xử lý kết quả\nTận dụng chức năng tool calling của mô hình gpt4-o với khả năng nhận diện và phân\ntích prompt từ yêu cầu mà người dùng đang hướng đến để xem xét việc sử dụng sự trợ\ngiúp từ các công cụ đã được thiết lập sẵn cho trợ lý ảo\na. Đặt lịch nhắc nhở, lên kế hoạch:\nHình5:Quytrìnhlênkếhoạch/lịchhẹncủatrợlýảo\nỨng dụng từ công trình nghiên cứu của Nitarshan Rajkumar và cộng sự năm 2022 [6], sử\ndụng phương pháp chuyển đổi từ text sang sql và khả năng tương tác với cơ sở dữ liệu\ntrong phạm vi các table lưu trữ dữ liệu nhắc nhở từ langchain cho phép mô hình có thể\nthực hiện các thao tác tìm kiếm thêm xóa sửa đối với các dữ liệu nhắc nhở dựa trên\nprompt của người dùng, đồng thời dữ liệu các lịch nhắc nhở sẽ luôn được đồng bộ lên\ngoogle calendar tương ứng với tài khoản google đã được liên kết với tài khoản hiện tại\nđang tương tác với trợ lý ảo, với tính năng parallel tool calling cho phép mô hình có thể\nthực hiện quá trình thêm bớt hay điều chỉnh dữ liệu nhắc nhở nhiều lần, điều này mang\nlại cho trợ lý ảo khả năng thiết lập hay lên một lịch trình học tập, làm việc một cách tự\nđộng và nhanh chóng\nb. Phân tích tìm kiếm thông tin từ internet:Hình6:Quytrìnhtìmkiếmthôngtintừinternetcủatrợlýảo\nVới các yêu cầu đòi hỏi những thông tin mang tính chính xác thời gian thực, các dữ liệu\nmang tính biến động nhiều và nằm ngoài dữ liệu được huấn luyện của mô hình, trợ lý ảo\nsẽ trực tiếp tìm kiếm và phân tích các thông tin từ internet để trả lời thông qua quy trình\nsau:\n- Bước 1: Thực hiện tìm kiếm các kết quả từ Google thông qua Serper API. Mô\nhình sẽ tự động phân tích các từ khóa liên quan đến câu hỏi từ prompt để thực\nhiện việc tìm kiếm.\n- Bước 2: Sau khi có được các URL cần thiết, sử dụng công cụ Puppeteer để scrape\ntoàn bộ nội dung từ các trang web.\n- Bước 3: Tiến hành tóm tắt, lại số dữ liệu vừa scrape được, để đảm bảo token tối\nđa cho phép với kỹ thuật map reduce từ Langchain để thực hiện tóm tắt tất cả dữ\nliệu cần thiết\n- Bước 4: Mô hình sẽ phân tích dữ liệu cuối cùng để đánh giá tính đáp ứng với câu\nhỏi. Nếu không đáp ứng, quy trình sẽ quay lại từ bước 1, tìm kiếm theo từ khóa\nkhác và lặp lại cho đến khi có câu trả lời phù hợp. Sau đó, mô hình ngôn ngữ sẽ\nđiều chỉnh lại câu từ để đưa ra thông tin tóm gọn mà người dùng mong muốn.\nVới mỗi câu trả lời liên quan đến việc tìm kiếm từ internet, trợ lý ảo sẽ luôn đính kèm\nđường link nguồn từ các trang web có kết quả phù hợp.\nc. Hỏi đáp về nội dung liên quan đến các file đã được phân tích\nỨng dụng công nghệ tạo sinh có tăng cường truy xuất (Retrieval Augmented\nGeneration) để có thể giúp cho mô hình ngôn ngữ có thể đưa ra các câu trả lời dựa trên\nnguồn kiến thức từ các tập dữ liệu lớn đã được phân tích trước đó và phòng tránh các\ntrường hợp “Hallucination”. Do đó với các trường hợp prompt yêu cầu trả lời về các\nthông tin liên quan đến nội dung từ các file đã được tải lên, trợ lý ảo sẽ thực hiện cơ chế\nretrieval quét toàn bộ vector trong database để xác định các phân đoạn tri thức\n(paragraphs) nào có ngữ nghĩa tương đồng với câu truy vấn của người dùng. Các\nparagraphs này sau đó được vào LLM để làm tăng context cho quá trình sinh ra câu trả\nlời, sau đó các paragraphs này được kết hợp với câu query ban đầu của user tạo thành 1câu prompt. Câu prompt này được bổ sung thêm context sau đó được đưa qua LLM để\nsinh ra câu phản hồi cuối cùng theo context bổ sung.\nIV. Xuất dữ liệu\nTận dụng khả năng hỗ trợ chunk stream từ mô hình ngôn ngữ, đề tài ứng dụng socket để\nhỗ trợ khả năng gửi liên tục các dữ liệu chunk được tạo ra về giao diện, đối với các\ntrường hợp mô hình yêu cầu sử dụng tool, socket cũng sẽ thực hiện trả về dữ liệu và quá\ntrình xử lý của các tool đó, điều này cho phép người dùng có thể nắm bắt được quá trình\nxử lý của trợ lý ảo và đặc biệt là giúp tăng trải nghiệm sử dụng, người dùng không cần\nphải đợi toàn bộ quá trình xử lý hoàn thành mà vẫn có thể giám sát được quy trình xử lý\nkhi đang tương tác trên giao diện ứng dụng.\nĐối với tính năng gọi video, đề tài áp dụng phương pháp chia nhỏ câu trả lời ra thành\nnhiều chunk từ đó sử dụng mô hình chuyển đổi tts-1 của openAI để chuyển đổi lần lượt\ncác dạng dữ liệu văn bản sang dữ liệu âm thanh, các dữ liệu âm thành này sau đó sẽ được\nphát lần lượt cho người dùng, quá trình này cho phép tối ưu được tổng thời gian xử lý\ncủa quá trình chuyển đổi bằng việc mô hình sẽ tốn ít thời gian để xử lý từng cụm dữ liệu\nnhỏ hơn là xử lý một lượng lớn dữ liệu trong một lần.\nE. Kết quả mong đợi:\n- Xây dựng thành công một hệ thống website tích hợp trợ lý ảo bằng AI tạo sinh giúp rút\nngắn khoảng cách tương tác giữa người dùng và máy móc thông qua khả năng nhận diện\nbối cảnh bằng thị giác và khả năng ghi nhớ dài hạn của trợ lý ảo, từ đó mang lại trải\nnghiệm hỗ trợ người dùng tốt hơn.\n- Triển khai áp dụng công nghệ tạo sinh có tăng cường truy xuất (Retrieval Augmented\nGeneration) kết hợp phương pháp proposal-based chunking để giúp tăng độ tin cậy cho\ncác đoạn dữ liệu được lưu vào vector database giúp cho mô hình có thể đưa vào các câu\ntrả lời chính xác hơn dựa trên các bộ dữ liệu đó.\n- Áp dụng thành công kĩ thuật như Tree of Thought Prompting (ToT) trong Prompt\nEngineering, giúp cho mô hình có thể tổ chức các chuỗi lập luận để phân tích và đưa ra\ncác quyết định chính xác trong việc ghi nhớ học tập thông tin từ người dùng, kết hợp với\nkhả năng retrieve từ vector database để đưa ra các thông tin từ các dữ liệu liên quan đến\nmục tiêu người dùng đang hướng đến.\n- Xây dựng thành công khả năng tìm kiếm thông tin từ internet để giúp trợ lý ảo có thể\nđưa ra những câu trả lời mang tính chất thời gian thực giúp người dùng nhanh chóng tiếp\n- Giải quyết cho bài toán tự động hoá quá trình lập kế hoạch với khả năng điều chỉnh lịch\ntrình tự động, đồng bộ với Google Calendar.F. Tài liệu tham khảo:\n[1] S. Siddesh, A. Ullas, B. Santosh, Artificial intelligence based voice assistant, tập\n978–1–7281–68234/20, IEEE,2020,p.593–596.\n[2] Nguyễn Tiến Dũng, Phạm Trung Thiên*, Lê Ngọc Dũng, Đỗ Văn Tỉnh,Vũ Xuân Tú,\nNguyễn Văn Hiệp, Nguyễn Ngọc Thể, NGHIÊN CỨU TRỢ LÝ ẢO ỨNG DỤNG TRÍ\nTUỆ NHÂNTẠO,Hồ ChíMinh: KHOAHỌC&CÔNG NGHỆ,2022.\n[3] Rohit Tamrakar, Niraj Wani, Design and Development of CHATBOT: AReview, Bhopal:\nINTERNATIONAL CONFERENCE On “Latest Trends in Civil, Mechanical and\nElectrical Engineering”,2021.\n[4] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao,\nKarthik Narasimhan, “Tree of Thoughts: Deliberate Problem Solving with Large\nLanguageModels”, 3Dec2023.\n[5] JieyiLong, “LargeLanguageModel GuidedTree-of-Thought”, 15May2023.\n[6] Nitarshan Rajkumar, Raymond Li, and Dzmitry Bahdanau. n.d. “Evaluating the\nText-to-SQL Capabilities ofLarge LanguageModels.”, 15Mar2022\n[7] Tong Chen, Hongwei Wang, Sihao Chen, Wenhao Yu♢, Kaixin Ma, Xinran Zhao,\nHongming Zhang, and Dong Yu. 2023. “Dense X Retrieval: What Retrieval Granularity\nShould WeUse?”, 12/2023.\nKế hoạch thực hiện:\nMô tả tóm tắt kế hoạch làm việc: Kế hoạch làm việc được thể hiện trong bảng sau:\nBảng 1. Mô tả tóm tắt kế hoạch làm việc\nCông việc T9 T10 T11 T12 T1\nNghiên cứu các công trình liên quan\nThiết kế và nâng cấp hệ thống\nTriển khai hệ thống\nKiểm thử và đánh giá\nVận hành và bảo trì\nViết và hoàn thiện báo cáoBảng 2. Chi tiết bảng kế hoạch thực hiện\nCông việc Cảnh\nĐề ra mục tiêu và lên kế hoạch cụ thể X\nTìm hiểu và tham khảo nguồn tài liệu; nghiên cứu những X\nkiến thức liên quan\nXây dựng giao diện, thiết kế hệ thống tích hợp các dịch vụ và API X\nĐánh giá, phân tích kết quả X\nViết báo cáo và báo cáo X\nXác nhận của CBHD TP. HCM, ngày….tháng …..năm…..\n(Ký tênvàghi rõhọtên) Sinh viên\n(Ký tênvàghi rõhọtên)"
# """
def agenticChunking(text):
    obj = hub.pull("wfh/proposal-indexing")
    llm = ChatOpenAI(model='gpt-3.5-turbo')
    runnable = obj | llm

    class Sentences(BaseModel):
        sentences: list[str]
        
    # Extraction
    extraction_chain = create_extraction_chain_pydantic(pydantic_schema=Sentences, llm=llm)
    def get_propositions(text):
        runnable_output = runnable.invoke({
            "input": text
        }).content
        propositions = extraction_chain.invoke(runnable_output)["text"][0].sentences
        return propositions
        
    paragraphs = text.split("\n\n")
    text_propositions = []
    for i, para in enumerate(paragraphs):
        propositions = get_propositions(para)
        text_propositions.extend(propositions)
        print (f"Done with {i}")

    print (f"You have {len(text_propositions)} propositions")
    print(text_propositions[:10])

    print("#### Agentic Chunking ####")

    from agentic_chunker import AgenticChunker
    ac = AgenticChunker()
    ac.add_propositions(text_propositions)
    print(ac.pretty_print_chunks())
    chunks = ac.get_chunks(get_type='list_of_strings')
    print(chunks)
    return chunks
    # documents = [Document(page_content=chunk, metadata={"source": "local"}) for chunk in chunks]
    # rag(documents, "agentic-chunks")